{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ced790b6d3ce23",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Rapport : Quantitative Structure-Activity Relationship\n",
    "Equipe : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c51bc67cc6e3b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **1 - Réprésentation des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "33c90b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1332996bcb29b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### **a) Analyse de l'ensemble des données**\n",
    "#### Analyse des critères statistiques des attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8a5b9743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154, 75)\n"
     ]
    }
   ],
   "source": [
    "# Lecture des données du xlsx\n",
    "data_file = \"QSAR_dataset.xlsx\"\n",
    "# Stockage des données dans un dataframe\n",
    "data = pd.read_excel(data_file,index_col=0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f04192c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apol</th>\n",
       "      <th>ASA+</th>\n",
       "      <th>ASA-</th>\n",
       "      <th>a_count</th>\n",
       "      <th>a_donacc</th>\n",
       "      <th>a_heavy</th>\n",
       "      <th>a_hyd</th>\n",
       "      <th>a_IC</th>\n",
       "      <th>a_nC</th>\n",
       "      <th>a_nCl</th>\n",
       "      <th>...</th>\n",
       "      <th>VSA</th>\n",
       "      <th>vsa_acc</th>\n",
       "      <th>vsa_hyd</th>\n",
       "      <th>vsa_pol</th>\n",
       "      <th>vsurf_A</th>\n",
       "      <th>vsurf_R</th>\n",
       "      <th>vsurf_S</th>\n",
       "      <th>vsurf_V</th>\n",
       "      <th>Weight</th>\n",
       "      <th>zagreb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>1.470000e+02</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.610698</td>\n",
       "      <td>105.781739</td>\n",
       "      <td>359.928668</td>\n",
       "      <td>23.909091</td>\n",
       "      <td>0.292208</td>\n",
       "      <td>18.875817</td>\n",
       "      <td>17.350649</td>\n",
       "      <td>33.912102</td>\n",
       "      <td>11.649351</td>\n",
       "      <td>3.110390</td>\n",
       "      <td>...</td>\n",
       "      <td>273.307303</td>\n",
       "      <td>8.076532</td>\n",
       "      <td>239.944812</td>\n",
       "      <td>9.086768</td>\n",
       "      <td>2.379611</td>\n",
       "      <td>-6.802721e+08</td>\n",
       "      <td>-66.497364</td>\n",
       "      <td>-2.501405</td>\n",
       "      <td>359.813016</td>\n",
       "      <td>101.350649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.951534</td>\n",
       "      <td>62.391286</td>\n",
       "      <td>111.225998</td>\n",
       "      <td>4.895461</td>\n",
       "      <td>0.862625</td>\n",
       "      <td>5.596428</td>\n",
       "      <td>5.028718</td>\n",
       "      <td>9.714722</td>\n",
       "      <td>2.472152</td>\n",
       "      <td>2.954031</td>\n",
       "      <td>...</td>\n",
       "      <td>52.783753</td>\n",
       "      <td>14.721655</td>\n",
       "      <td>59.915749</td>\n",
       "      <td>15.129738</td>\n",
       "      <td>2.637952</td>\n",
       "      <td>8.247861e+09</td>\n",
       "      <td>73.647379</td>\n",
       "      <td>2.807324</td>\n",
       "      <td>132.955027</td>\n",
       "      <td>33.487395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.148172</td>\n",
       "      <td>8.778115</td>\n",
       "      <td>122.917570</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>140.102050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.651054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>-1.000000e+11</td>\n",
       "      <td>-209.769584</td>\n",
       "      <td>-8.247237</td>\n",
       "      <td>128.174000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.534723</td>\n",
       "      <td>70.909811</td>\n",
       "      <td>330.864750</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>30.541887</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>246.182178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203.302167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124434</td>\n",
       "      <td>2.696068e-01</td>\n",
       "      <td>-132.566487</td>\n",
       "      <td>-5.058933</td>\n",
       "      <td>291.992000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.579689</td>\n",
       "      <td>98.659012</td>\n",
       "      <td>389.503510</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>31.868664</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>281.160615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>253.968020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376156</td>\n",
       "      <td>8.136986e-01</td>\n",
       "      <td>-10.648449</td>\n",
       "      <td>-0.411358</td>\n",
       "      <td>360.881990</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.401845</td>\n",
       "      <td>139.629990</td>\n",
       "      <td>427.294460</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>37.087944</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>295.503230</td>\n",
       "      <td>13.566921</td>\n",
       "      <td>272.261230</td>\n",
       "      <td>13.566921</td>\n",
       "      <td>4.786711</td>\n",
       "      <td>9.972196e+00</td>\n",
       "      <td>-3.509363</td>\n",
       "      <td>-0.133136</td>\n",
       "      <td>410.317990</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.422001</td>\n",
       "      <td>356.764860</td>\n",
       "      <td>622.904600</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>86.319427</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>432.120120</td>\n",
       "      <td>59.150364</td>\n",
       "      <td>475.687620</td>\n",
       "      <td>59.150364</td>\n",
       "      <td>7.429943</td>\n",
       "      <td>1.611555e+01</td>\n",
       "      <td>-0.338738</td>\n",
       "      <td>-0.013318</td>\n",
       "      <td>959.170960</td>\n",
       "      <td>246.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             apol        ASA+        ASA-     a_count    a_donacc     a_heavy  \\\n",
       "count  154.000000  152.000000  153.000000  154.000000  154.000000  153.000000   \n",
       "mean    34.610698  105.781739  359.928668   23.909091    0.292208   18.875817   \n",
       "std      5.951534   62.391286  111.225998    4.895461    0.862625    5.596428   \n",
       "min     17.148172    8.778115  122.917570   12.000000    0.000000   10.000000   \n",
       "25%     31.534723   70.909811  330.864750   22.000000    0.000000   17.000000   \n",
       "50%     35.579689   98.659012  389.503510   22.000000    0.000000   18.000000   \n",
       "75%     38.401845  139.629990  427.294460   25.750000    0.000000   19.000000   \n",
       "max     52.422001  356.764860  622.904600   43.000000    4.000000   43.000000   \n",
       "\n",
       "            a_hyd        a_IC        a_nC       a_nCl  ...         VSA  \\\n",
       "count  154.000000  153.000000  154.000000  154.000000  ...  154.000000   \n",
       "mean    17.350649   33.912102   11.649351    3.110390  ...  273.307303   \n",
       "std      5.028718    9.714722    2.472152    2.954031  ...   52.783753   \n",
       "min      6.000000   12.000000    6.000000    0.000000  ...  140.102050   \n",
       "25%     16.000000   30.541887   12.000000    0.000000  ...  246.182178   \n",
       "50%     17.000000   31.868664   12.000000    4.000000  ...  281.160615   \n",
       "75%     18.000000   37.087944   12.000000    6.000000  ...  295.503230   \n",
       "max     40.000000   86.319427   20.000000   10.000000  ...  432.120120   \n",
       "\n",
       "          vsa_acc     vsa_hyd     vsa_pol     vsurf_A       vsurf_R  \\\n",
       "count  154.000000  154.000000  154.000000  154.000000  1.470000e+02   \n",
       "mean     8.076532  239.944812    9.086768    2.379611 -6.802721e+08   \n",
       "std     14.721655   59.915749   15.129738    2.637952  8.247861e+09   \n",
       "min      0.000000   67.651054    0.000000    0.011998 -1.000000e+11   \n",
       "25%      0.000000  203.302167    0.000000    0.124434  2.696068e-01   \n",
       "50%      0.000000  253.968020    0.000000    0.376156  8.136986e-01   \n",
       "75%     13.566921  272.261230   13.566921    4.786711  9.972196e+00   \n",
       "max     59.150364  475.687620   59.150364    7.429943  1.611555e+01   \n",
       "\n",
       "          vsurf_S     vsurf_V      Weight      zagreb  \n",
       "count  141.000000  136.000000  154.000000  154.000000  \n",
       "mean   -66.497364   -2.501405  359.813016  101.350649  \n",
       "std     73.647379    2.807324  132.955027   33.487395  \n",
       "min   -209.769584   -8.247237  128.174000   46.000000  \n",
       "25%   -132.566487   -5.058933  291.992000   88.000000  \n",
       "50%    -10.648449   -0.411358  360.881990   94.000000  \n",
       "75%     -3.509363   -0.133136  410.317990  106.000000  \n",
       "max     -0.338738   -0.013318  959.170960  246.000000  \n",
       "\n",
       "[8 rows x 74 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistiques descriptives des 74 attributs\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "519a25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Il faut éléminer les outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51614ac9",
   "metadata": {},
   "source": [
    "\n",
    "#### Prétraitement des données\n",
    "**Traitement des données manquantes** \\\n",
    "Nous avons décidé de procéder au traitement des données manquantes par imputation, au lieu de simplement supprimer les dites données. Les objets n'étant pas nombreux, il y a un risque d'obtenir des résultats faussés avec ce second choix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "86c430ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détermination du type, du nombre et du pourcentage de valeurs manquantes par attribut\n",
    "nb_m = data.isnull().sum().sort_values()\n",
    "ratio_m = (data.isnull().sum()/data.shape[0]).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "35fbcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "manquant = pd.concat([nb_m, ratio_m], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "30d138d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Types  Nb manquants  % de manquants\n",
      "a_IC     float64             1        0.006494\n",
      "a_heavy  float64             1        0.006494\n",
      "ASA-     float64             1        0.006494\n",
      "ASA+     float64             2        0.012987\n",
      "vsurf_R  float64             7        0.045455\n",
      "vsurf_S  float64            13        0.084416\n",
      "vsurf_V  float64            18        0.116883\n"
     ]
    }
   ],
   "source": [
    "# Affichage de ces données\n",
    "df_manquants = pd.DataFrame({'Types': data[list(manquant.index.values)].dtypes,\n",
    "                       'Nb manquants': nb_m,\n",
    "                      '% de manquants': ratio_m,})\n",
    "# On ne se concentre que sur les attributs aux valeurs manquantes\n",
    "df_ADM = df_manquants[df_manquants[\"Nb manquants\"]>0]\n",
    "print(df_ADM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ec644e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter le ratio total et le nombre total de manquants faire une petite analyse dessus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560b862",
   "metadata": {},
   "source": [
    "Tout d'abord, on observe que tous les attributs manquants sont numériques. De plus, on remarque que la proportion de données manquantes est différente pour chaque attribut, on n'est donc pas dans le cas du MMCA (Données manquantes de Manière Complètement Aléatoire)<sup>**1**</sup>. On considère que nos données sont dans le cas MA (Manquantes Aléatoirement), car c'est la situation la plus courante<sup>**2**</sup>. Pour traiter les données MA il y a deux possibilités qui s'offrent à nous<sup>**3**</sup> :\n",
    "- Imputation par régression linéaire\n",
    "- Imputation multiple (On choisit kNN car c'est un algorithme qu'on a étudié en cours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049d7a2",
   "metadata": {},
   "source": [
    "Nous avons choisi d'opter pour l'imputation kNN, car celle-ci peut effectuer une imputation plus simplement même s'il y a des valeurs NaN dans le Dataframe.\n",
    "Afin de procéder à l'imputation des valeurs manquantes de ces attributs, il faut trouver ceux qui leur sont fortement corrélés. Pour éviter de se trouver dans une impasse, nous avons décidé d'ignorer, lors de l'identification des attributs corrélés à un ADM, les autres ADM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c6eed",
   "metadata": {},
   "source": [
    "Nous allons d'abord procéder à une normalisation des données pour éviter des biais systémiques<sup>**5**</sup>, et on procède à un \"one-hot encoding\" pour transformer l'attribut \"Class\" en attribut numérique et permettre l'imputation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6efc45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des attributs avec des données manquantes\n",
    "missing_attributes = [\"a_IC\",\"a_heavy\",\"ASA-\",\"ASA+\",\"vsurf_R\",\"vsurf_S\",\"vsurf_V\"]\n",
    "\n",
    "# One hot encoding pour l'attribut Class\n",
    "data = pd.get_dummies(data=data, columns=[\"Class\"])\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns = data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f4b64",
   "metadata": {},
   "source": [
    "**Imputation KNN (Optimisée)** \n",
    "\\\n",
    "\n",
    "Pour l'imputation multiple, nous allons procéder à une imputation kNN avec KNNImputer, puis optimiser notre modèle grâce à RandomForestRegressor(), qui permet de prédire des valeurs numériques. Elle permet de réduire le surapprentissage et d'améliorer la précision.https://www.kaggle.com/code/sangyunkang/knn-imputation\n",
    "Pour déterminer le nombre de voisins k à prendre en compte, nous avons décidé d'utiliser une fonction, et de mesurer le taux d'erreur avec MSE pour plusieurs valeurs de k, ce qui nous permettre de nous décider.  (https://ai.plainenglish.io/understanding-common-regression-evaluation-metrics-mae-mse-rmse-r2-and-adjusted-r2-6c5709e614c4)MSE and RMSE are appropriate when larger errors need to be penalized, provided outliers are managed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b3257fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le but de cette fonction est de permettre l'évaluation du meilleur nombre de voisins pour l'imputation kNN\n",
    "def eval_kNNimputation(attribute):\n",
    "        res = []\n",
    "        for k in range(1,155):\n",
    "                # Imputation kNN\n",
    "                imputer = KNNImputer(n_neighbors=k)\n",
    "                imputed = imputer.fit_transform(data)\n",
    "                data_kNNimputed = pd.DataFrame(imputed, columns=data.columns)\n",
    "                # Données qui vont permettre l'entraînement et le test du modèle\n",
    "                X = data_kNNimputed.drop(attribute, axis=1)\n",
    "                Y = data_kNNimputed[attribute]\n",
    "                # Fixer le random state permet d'obtenir les mêmes valeurs peu importe le nombre d'exécutions\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "                # Mis en place du modèle sur les données imputées\n",
    "                model = RandomForestRegressor()\n",
    "                model.fit(X_train, y_train)\n",
    "                predict = model.predict(X_test)\n",
    "                # Calcul du RMSE\n",
    "                error = mean_squared_error(y_test, predict)\n",
    "                res.append({'K': k, 'RMSE': error})\n",
    "        \n",
    "        return res\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a4676218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K': 154, 'RMSE': 0.0016012047592208918}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNNimputation_RMSE = []\n",
    "for attribute in missing_attributes:\n",
    "    kNNimputation_RMSE.append(eval_kNNimputation(attribute))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6354dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction permettant d'obtenir la liste des attributs fortement corrélés à attribut_name \n",
    "# On recherche au minimum un attribut fortement corrélé.\n",
    "# Le paramètre count_missing_attributes est un booléen permettant de considérer (ou non)\n",
    "# les autres attributs manquants\n",
    "def correlated_attributes(attribute_name):\n",
    "    coef = 0.9\n",
    "    # Dataframe contenant les attributs fortement corrélés\n",
    "    data_corr = data_noclass.loc[:, data_noclass.corr()[attribute_name] > coef]\n",
    "    \n",
    "    data_corr = data_corr.drop(missing_attributes, axis=1, errors='ignore')\n",
    "    while data_corr.empty:\n",
    "        coef -= 0.1\n",
    "        data_corr = data_noclass.loc[:, data_noclass.corr()[attribute_name] > coef]\n",
    "        data_corr = data_corr.drop(missing_attributes, axis=1, errors='ignore')\n",
    "\n",
    "    res_list = list(data_corr.columns)\n",
    "\n",
    "    return res_list,coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0946c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADM :  a_IC \n",
      "  liste des attributs corrélés :  ['a_count', 'bpol'] \n",
      "      coeficient de corrélation :  0.7000000000000001\n",
      "ADM :  a_heavy \n",
      "  liste des attributs corrélés :  ['a_hyd', 'CASA-', 'chi0', 'chi1', 'DCASA', 'VAdjMa', 'VDistMa', 'vdw_vol', 'zagreb'] \n",
      "      coeficient de corrélation :  0.9\n",
      "ADM :  ASA- \n",
      "  liste des attributs corrélés :  ['DASA', 'PEOE_VSA_NEG', 'Weight'] \n",
      "      coeficient de corrélation :  0.9\n",
      "ADM :  ASA+ \n",
      "  liste des attributs corrélés :  ['a_nH'] \n",
      "      coeficient de corrélation :  0.9\n",
      "ADM :  vsurf_R \n",
      "  liste des attributs corrélés :  ['apol', 'a_nC', 'a_nH', 'chi0v_C', 'chi0_C', 'chi1v_C', 'chi1_C', 'mr', 'PC-', 'SlogP', 'SMR', 'std_dim2'] \n",
      "      coeficient de corrélation :  0.10000000000000014\n",
      "ADM :  vsurf_S \n",
      "  liste des attributs corrélés :  ['chi1v_C', 'chi1_C'] \n",
      "      coeficient de corrélation :  0.40000000000000013\n",
      "ADM :  vsurf_V \n",
      "  liste des attributs corrélés :  ['chi1v_C', 'chi1_C'] \n",
      "      coeficient de corrélation :  0.40000000000000013\n"
     ]
    }
   ],
   "source": [
    "for attribute in missing_attributes:\n",
    "    print(\"ADM : \",attribute,\"\\n\",\" liste des attributs corrélés : \",correlated_attributes(attribute)[0],\"\\n\",\n",
    "          \"     coeficient de corrélation : \",correlated_attributes(attribute)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2616e",
   "metadata": {},
   "source": [
    "Nous allons maintenant procéder à la régression linéaire de chaque ADM, avec visualisation des données tests en fonction des données prédites. De plus, nous avons calculé le coefficient de détermination, donnant la qualité de prédiction de la régression linéaire, et les valeurs d'erreurs absolues moyennes que l'on comparera à celle de l'imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2a47d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste contenant les erreurs absolues moyennes\n",
    "linearR_MAE = []\n",
    "# Résultats de la régression linéaires\n",
    "linearR_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "449b8b70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m         linearR_results\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Exécution de la fonction                      \u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mlinearRegression_imputation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[176], line 13\u001b[0m, in \u001b[0;36mlinearRegression_imputation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m Y \u001b[38;5;241m=\u001b[39m data_noNaN[attribute]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Création du modèle de régression\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# On lui donne en données d'etraînement toutes les données qui ne sont pas nulles\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Il faut qu'on prédise les données avec les valeurs manquantes\u001b[39;00m\n\u001b[0;32m     15\u001b[0m predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data_noclass\u001b[38;5;241m.\u001b[39mdrop(attribute))\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:578\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    574\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    576\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 578\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1192\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1187\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m     )\n\u001b[1;32m-> 1192\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1208\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1210\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1003\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1000\u001b[0m     )\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1003\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "data_impLinear = data\n",
    "\n",
    "def linearRegression_imputation():\n",
    "    for attribute in missing_attributes:\n",
    "        # Dataframe des données sans les lignes aux valeurs manquantes dans pour la colonne étudiée\n",
    "        data_noNaN = data_noclass[~data_noclass[attribute].isna()]\n",
    "        # Dataframe contenant les données d'entrainement\n",
    "        X = data_noNaN.drop(attribute,axis=1)\n",
    "        # Datframe de l'attribut cible\n",
    "        Y = data_noNaN[attribute]\n",
    "        # Création du modèle de régression\n",
    "        # On lui donne en données d'etraînement toutes les données qui ne sont pas nulles\n",
    "        model = LinearRegression().fit(X = X,y = Y)\n",
    "        # Il faut qu'on prédise les données avec les valeurs manquantes\n",
    "        predict = model.predict(data_noclass.drop(attribute))\n",
    "\n",
    "        data_impLinear[attribute].fillna(predict)\n",
    "\n",
    "\n",
    "        # Calcul de l'erreur absolue moyenne et sauvegarde dans la liste dédiée\n",
    "        MAE = metrics.mean_absolute_error(y_test, predict)\n",
    "        linearR_MAE.append(round(MAE*100,3))\n",
    "        r2_score = model.score(X, Y)\n",
    "        res = [list(y_test),list(predict),r2_score]\n",
    "        linearR_results.append(res)\n",
    "\n",
    "\n",
    "# Exécution de la fonction                      \n",
    "linearRegression_imputation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebc64d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ASA+\n- ASA-\n- CASA+\n- CASA-\n- DASA\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[892], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Exécution de la fonction précédente                     \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlinearRegression_imputation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data_impLinear\u001b[38;5;241m.\u001b[39misna\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#observation des résultats de la régression linéaire\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[891], line 16\u001b[0m, in \u001b[0;36mlinearRegression_imputation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\u001b[38;5;241m.\u001b[39mfit(X \u001b[38;5;241m=\u001b[39m X,y \u001b[38;5;241m=\u001b[39m Y)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Il faut qu'on prédise les données avec les valeurs manquantes\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_noclass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m data_impLinear[attribute]\u001b[38;5;241m.\u001b[39mfillna(predict)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Calcul de l'erreur absolue moyenne et sauvegarde dans la liste dédiée\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:286\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:269\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    267\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 269\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ASA+\n- ASA-\n- CASA+\n- CASA-\n- DASA\n- ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_impLinear.isna\n",
    "#observation des résultats de la régression linéaire\n",
    "def visualisation_linearRegression():\n",
    "    i =1\n",
    "    fig = make_subplots(rows=2, cols=4,subplot_titles=missing_attributes)\n",
    "    for ADM in linearR_results:\n",
    "        coef = round(ADM[2]*100,4)\n",
    "        if i <= 4 :\n",
    "            fig.add_trace(\n",
    "            go.Scatter(x=ADM[0], y=ADM[1],mode=\"markers\",name=coef),\n",
    "            row=1, col=i\n",
    "            )\n",
    "        \n",
    "        else :\n",
    "            fig.add_trace(\n",
    "            go.Scatter(x=ADM[0], y=ADM[1],mode=\"markers\",name=coef),\n",
    "            row=2, col=i%4)\n",
    "        i+=1\n",
    "    \n",
    "    fig.update_layout(height=600, width=1000, title_text=\"Résulats de la régression linéaire des ADM\",legend_title=\"Coefficients de corrélation en %\")\n",
    "    fig.show()\n",
    "\n",
    "visualisation_linearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810221e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536784c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of          apol      ASA+      ASA-   a_count  a_donacc   a_heavy     a_hyd  \\\n",
       "0    0.684213  0.035935  0.999003  1.000000      0.00  1.000000  1.000000   \n",
       "1    0.164036  0.422997  0.067557  0.193548      0.00  0.000000  0.117647   \n",
       "2    0.730622  0.086779  0.753228  0.322581      0.00  0.363636  0.470588   \n",
       "3    0.605576  0.107740  0.597048  0.354839      0.25  0.272727  0.294118   \n",
       "4    0.687723  0.136829  0.715166  0.322581      0.00  0.333333  0.441176   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "149  0.516128  0.286831  0.493783  0.322581      0.00  0.212121  0.323529   \n",
       "150  0.562859  0.189654  0.608770  0.322581      0.00  0.272727  0.323529   \n",
       "151  0.401424  0.477292  0.111778  0.387097      0.00  0.121212  0.235294   \n",
       "152  0.458158  0.276278  0.421494  0.290323      0.00  0.212121  0.235294   \n",
       "153  0.501215  0.490079  0.112692  0.451613      0.00  0.181818  0.294118   \n",
       "\n",
       "         a_IC      a_nC  a_nCl  ...       VSA   vsa_acc   vsa_hyd   vsa_pol  \\\n",
       "0    0.506522  0.571429    0.0  ...  0.963492  0.458727  0.710049  0.458727   \n",
       "1    0.078571  0.285714    0.0  ...  0.038604  0.000000  0.154971  0.000000   \n",
       "2    0.132787  0.428571    1.0  ...  0.679148  0.000000  0.680780  0.000000   \n",
       "3    0.360910  0.285714    0.8  ...  0.526976  0.042329  0.478975  0.042329   \n",
       "4    0.195893  0.428571    0.9  ...  0.651510  0.000000  0.635947  0.000000   \n",
       "..        ...       ...    ...  ...       ...       ...       ...       ...   \n",
       "149  0.267341  0.428571    0.5  ...  0.460435  0.000000  0.456618  0.000000   \n",
       "150  0.307097  0.428571    0.6  ...  0.520683  0.229363  0.462708  0.229363   \n",
       "151  0.154964  0.571429    0.0  ...  0.200856  0.000000  0.243282  0.000000   \n",
       "152  0.285512  0.428571    0.4  ...  0.370703  0.000000  0.334300  0.000000   \n",
       "153  0.174815  0.714286    0.0  ...  0.251400  0.000000  0.254107  0.000000   \n",
       "\n",
       "      vsurf_A  vsurf_R   vsurf_S   vsurf_V    Weight  zagreb  \n",
       "0    0.485101      1.0  0.514899  0.514899  0.703882    1.00  \n",
       "1    0.003791      1.0  0.996209  0.996209  0.000000    0.02  \n",
       "2    0.004876      1.0  0.995124  0.995124  0.445836    0.36  \n",
       "3    0.668852      1.0  0.331148  0.331148  0.355706    0.42  \n",
       "4    0.016949      1.0  0.983051  0.983051  0.404385    0.33  \n",
       "..        ...      ...       ...       ...       ...     ...  \n",
       "149  0.023894      1.0  0.976106  0.976106  0.238584    0.21  \n",
       "150  0.931929      1.0  0.068071  0.068071  0.298074    0.27  \n",
       "151  0.011611      1.0  0.983796  0.988389  0.060241    0.15  \n",
       "152  0.026834      1.0  0.950658  0.973166  0.213961    0.25  \n",
       "153  0.004924      1.0  0.995076  0.995076  0.089148    0.24  \n",
       "\n",
       "[154 rows x 74 columns]>"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b243320",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [153, 154]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[840], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         MAE \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mmean_absolute_error(y_true, y_imputed)\n\u001b[0;32m      7\u001b[0m         kNN_imputation_MAE\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mround\u001b[39m(MAE\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m \u001b[43mkNN_imputation_MAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[840], line 6\u001b[0m, in \u001b[0;36mkNN_imputation_MAE\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m y_true \u001b[38;5;241m=\u001b[39m data_noclass[attribute]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m y_imputed \u001b[38;5;241m=\u001b[39m data_kNN[attribute]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m----> 6\u001b[0m MAE \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_imputed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m kNN_imputation_MAE\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mround\u001b[39m(MAE\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:207\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    144\u001b[0m     {\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m ):\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    211\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    104\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:430\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    428\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    433\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [153, 154]"
     ]
    }
   ],
   "source": [
    "kNN_imputation_res = []\n",
    "def kNN_imputation_MAE():\n",
    "    for attribute in missing_attributes:\n",
    "        y_true = data_noclass[attribute].dropna().values\n",
    "        y_imputed = data_kNN[attribute].values\n",
    "        MAE = metrics.mean_absolute_error(y_true, y_imputed)\n",
    "        kNN_imputation_MAE.append(round(MAE*100,3))\n",
    "\n",
    "kNN_imputation_MAE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afb704",
   "metadata": {},
   "source": [
    "Nous allons maintenant observer les différences d'erreurs moyennes absolues entre l'imputation par régression linéaire et k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd46dbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'builtins.function' received for the 'y' property of histogram\n        Received value: <function kNN_imputation_MAE at 0x0000020DDA57C9A0>\n\n    The 'y' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[767], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure(layout_title_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComparaison des erreurs absolues moyennes entre l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputaion par régression linéaire et l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputation kNN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m fig\u001b[38;5;241m.\u001b[39madd_trace(go\u001b[38;5;241m.\u001b[39mHistogram(histfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39mlinearR_MAE, x\u001b[38;5;241m=\u001b[39mmissing_attributes, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImputation ar régression linéaire\u001b[39m\u001b[38;5;124m\"\u001b[39m,marker_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#B784B7\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m fig\u001b[38;5;241m.\u001b[39madd_trace(\u001b[43mgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHistogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkNN_imputation_MAE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImputation kNN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmarker_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m#E6A4B4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\graph_objs\\_histogram.py:3189\u001b[0m, in \u001b[0;36mHistogram.__init__\u001b[1;34m(self, arg, alignmentgroup, autobinx, autobiny, bingroup, cliponaxis, constraintext, cumulative, customdata, customdatasrc, error_x, error_y, histfunc, histnorm, hoverinfo, hoverinfosrc, hoverlabel, hovertemplate, hovertemplatesrc, hovertext, hovertextsrc, ids, idssrc, insidetextanchor, insidetextfont, legend, legendgroup, legendgrouptitle, legendrank, legendwidth, marker, meta, metasrc, name, nbinsx, nbinsy, offsetgroup, opacity, orientation, outsidetextfont, selected, selectedpoints, showlegend, stream, text, textangle, textfont, textposition, textsrc, texttemplate, uid, uirevision, unselected, visible, x, xaxis, xbins, xcalendar, xhoverformat, xsrc, y, yaxis, ybins, ycalendar, yhoverformat, ysrc, **kwargs)\u001b[0m\n\u001b[0;32m   3187\u001b[0m _v \u001b[38;5;241m=\u001b[39m y \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n\u001b[0;32m   3188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3189\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m _v\n\u001b[0;32m   3190\u001b[0m _v \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   3191\u001b[0m _v \u001b[38;5;241m=\u001b[39m yaxis \u001b[38;5;28;01mif\u001b[39;00m yaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m _v\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\basedatatypes.py:4874\u001b[0m, in \u001b[0;36mBasePlotlyType.__setitem__\u001b[1;34m(self, prop, value)\u001b[0m\n\u001b[0;32m   4870\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_array_prop(prop, value)\n\u001b[0;32m   4872\u001b[0m     \u001b[38;5;66;03m# ### Handle simple property ###\u001b[39;00m\n\u001b[0;32m   4873\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4874\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4876\u001b[0m     \u001b[38;5;66;03m# Make sure properties dict is initialized\u001b[39;00m\n\u001b[0;32m   4877\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_props()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\basedatatypes.py:5218\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[1;34m(self, prop, val)\u001b[0m\n\u001b[0;32m   5216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   5217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 5218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m   5220\u001b[0m \u001b[38;5;66;03m# val is None\u001b[39;00m\n\u001b[0;32m   5221\u001b[0m \u001b[38;5;66;03m# -----------\u001b[39;00m\n\u001b[0;32m   5222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5223\u001b[0m     \u001b[38;5;66;03m# Check if we should send null update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\basedatatypes.py:5213\u001b[0m, in \u001b[0;36mBasePlotlyType._set_prop\u001b[1;34m(self, prop, val)\u001b[0m\n\u001b[0;32m   5210\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_validator(prop)\n\u001b[0;32m   5212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 5213\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_coerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   5215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_invalid:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:412\u001b[0m, in \u001b[0;36mDataArrayValidator.validate_coerce\u001b[1;34m(self, v)\u001b[0m\n\u001b[0;32m    410\u001b[0m     v \u001b[38;5;241m=\u001b[39m to_scalar_or_list(v)\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 412\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_invalid_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_plotly_utils\\basevalidators.py:296\u001b[0m, in \u001b[0;36mBaseValidator.raise_invalid_val\u001b[1;34m(self, v, inds)\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[0;32m    294\u001b[0m                 name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 296\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    297\u001b[0m \u001b[38;5;250m            \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m    Invalid value of type {typ} received for the '{name}' property of {pname}\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;124;03m        Received value: {v}\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03m{valid_clr_desc}\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    302\u001b[0m                 name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    303\u001b[0m                 pname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_name,\n\u001b[0;32m    304\u001b[0m                 typ\u001b[38;5;241m=\u001b[39mtype_str(v),\n\u001b[0;32m    305\u001b[0m                 v\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(v),\n\u001b[0;32m    306\u001b[0m                 valid_clr_desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription(),\n\u001b[0;32m    307\u001b[0m             )\n\u001b[0;32m    308\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: \n    Invalid value of type 'builtins.function' received for the 'y' property of histogram\n        Received value: <function kNN_imputation_MAE at 0x0000020DDA57C9A0>\n\n    The 'y' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fig = go.Figure(layout_title_text=\"Comparaison des erreurs absolues moyennes entre l'imputaion par régression linéaire et l'imputation kNN\")\n",
    "fig.add_trace(go.Histogram(histfunc=\"min\", y=linearR_MAE, x=missing_attributes, name=\"Imputation ar régression linéaire\",marker_color=\"#B784B7\"))\n",
    "fig.add_trace(go.Histogram(histfunc=\"min\", y=kNN_imputation_MAE, x=missing_attributes, name=\"Imputation kNN\",marker_color=\"#E6A4B4\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8d001",
   "metadata": {},
   "source": [
    "On en déduit donc, d'après les résultats précédents, qu'il est plus cohérent de considérer les autres ADM lors de l'imputation par régression linéaire. Cependant, en observant la liste des attributs corrélés pour chaque ADM, on se rend compte ue pour la meilleure corrélation possible, certains ADM dépendant d'autres ADM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c55b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADM :  a_IC \n",
      "  liste des attributs corrélés :  ['a_count', 'a_heavy', 'bpol', 'CASA+', 'chi0', 'chi1', 'diameter', 'PC+', 'PEOE_VSA_PNEG', 'PEOE_VSA_POL', 'radius', 'std_dim1', 'TPSA', 'VDistEq', 'VDistMa', 'vdw_vol', 'VSA']\n",
      "ADM :  a_heavy \n",
      "  liste des attributs corrélés :  ['a_hyd', 'CASA-', 'chi0', 'chi1', 'DCASA', 'VAdjMa', 'VDistMa', 'vdw_vol', 'zagreb']\n",
      "ADM :  ASA- \n",
      "  liste des attributs corrélés :  ['DASA', 'PEOE_VSA_NEG', 'Weight']\n",
      "ADM :  ASA+ \n",
      "  liste des attributs corrélés :  ['a_nH', 'CASA+', 'chi0v_C', 'chi0_C', 'chi1v_C', 'chi1_C', 'std_dim2', 'VAdjEq']\n",
      "ADM :  vsurf_R \n",
      "  liste des attributs corrélés :  ['apol', 'ASA+', 'a_IC', 'a_nC', 'a_nH', 'chi0v_C', 'chi0_C', 'chi1v_C', 'chi1_C', 'mr', 'PC-', 'SlogP', 'SMR', 'std_dim2', 'vsurf_S']\n",
      "ADM :  vsurf_S \n",
      "  liste des attributs corrélés :  ['chi1v_C', 'chi1_C', 'vsurf_V']\n",
      "ADM :  vsurf_V \n",
      "  liste des attributs corrélés :  ['chi1v_C', 'chi1_C', 'vsurf_S']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b058f42",
   "metadata": {},
   "source": [
    "Création d'une fonction permettant de remplir les données manquantes d'un attribut donné en paramètres, en utilisant une régression linéaire stochastique. PQ ?\n",
    "Réalisée à l'aide de la référence  4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644546c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf199c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_IC\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[384], line 34\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mmean_absolute_error(y_test, predict))\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#fill_missing_data(\"a_IC\")\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mfill_missing_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#fill_missing_data(\"ASA-\")\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#fill_missing_data(\"ASA+\")\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#fill_missing_data(\"vsurf_R\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m#a = random_data[random_data[attribute].isna()]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[384], line 20\u001b[0m, in \u001b[0;36mfill_missing_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, Y)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Création du modèle de régression\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Création d'un dataframe pour observer les données\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:578\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    574\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    576\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 578\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1192\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1187\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m     )\n\u001b[1;32m-> 1192\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1208\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1210\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1003\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1000\u001b[0m     )\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1003\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "312eed9922bc9c2f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe9b98e9d738a3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6e9709bc9de11",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2 - Mesures de distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb5e3ddccb485f4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c0c6a332178ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71072e1ff3d630",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "3 - Choix du modèle de classification"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a20a4e4585c0af68",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def ok():\n",
    "    return 58"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aafcefc9314a0d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec076eaf2b37888",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "4 - Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d852fe4b9c014ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#okokoibn\n",
    "def fun():\n",
    "    return 897"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518c5fc",
   "metadata": {},
   "source": [
    "### **Références**\n",
    "\n",
    "1. https://stefvanbuuren.name/fimd/sec-MCAR.html\n",
    "2. https://medium.com/analytics-vidhya/different-types-of-missing-data-59c87c046bf7\n",
    "3. https://www.datacamp.com/tutorial/techniques-to-handle-missing-data-values\n",
    "4. https://www.kaggle.com/code/shashankasubrahmanya/missing-data-imputation-using-regression\n",
    "5. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3489534/#:%7E:text=We%20suggest%20that%20normalization%20be,imputation%2C%20significance%20analysis%20and%20visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
